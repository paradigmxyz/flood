{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0bdb406",
   "metadata": {},
   "source": [
    "# `flood` Load Test Report\n",
    "\n",
    "\n",
    "### Contents\n",
    "1. [Test Summary](#Test-Summary)\n",
    "2. [Tests](#Tests)\n",
    "    1. [Test: eth_getStorageAt](#Test:-eth_getStorageAt)\n",
    "\n",
    "### Report Generation\n",
    "\n",
    "*This report was generated by `flood`. See the `flood report --help` command for report generation options. This report can be executed as a Python notebook using the `.ipynb` version of this file.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import polars as pl\n",
    "import toolstr\n",
    "import tooltime\n",
    "\n",
    "import flood\n",
    "\n",
    "flood.user_io.styles = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c719eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "test_paths = {\n",
    "    'eth_getStorageAt': '/var/folders/ml/dymw9nkx51j7scsxc3qpqvl80000gp/T/tmpcljzupq2',\n",
    "}\n",
    "\n",
    "metrics = ['success', 'throughput', 'p50', 'p90', 'p99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ef8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "test_payloads = {\n",
    "    test_name: flood.load_single_run_test_payload(test_path)\n",
    "    for test_name, test_path in test_paths.items()\n",
    "}\n",
    "\n",
    "results_payloads = {\n",
    "    test_name: flood.load_single_run_results_payload(output_dir=test_path)\n",
    "    for test_name, test_path in test_paths.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066624e",
   "metadata": {},
   "source": [
    "# Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ef14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test list\n",
    "\n",
    "toolstr.print_text_box('Tests')\n",
    "for t, test_name in enumerate(results_payloads.keys()):\n",
    "    print(str(t + 1) + '.', test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b21425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test durations\n",
    "\n",
    "time_per_test = {}\n",
    "time_per_condition = {}\n",
    "\n",
    "for test_name in results_payloads:\n",
    "    results = results_payloads[test_name][\"results\"]\n",
    "    time_per_test[test_name] = 0\n",
    "    for condition_name in results.keys():\n",
    "        time_per_condition.setdefault(condition_name, 0)\n",
    "        time = sum(results[condition_name][\"actual_duration\"]) + sum(\n",
    "            results[condition_name][\"final_wait_time\"]\n",
    "        )\n",
    "        time_per_test[test_name] += time\n",
    "        time_per_condition[condition_name] += time\n",
    "\n",
    "toolstr.print_text_box('Total time')\n",
    "toolstr.print(tooltime.timelength_to_phrase(int(sum(time_per_test.values()))))\n",
    "print()\n",
    "\n",
    "toolstr.print_text_box('Total time per test')\n",
    "rows = list(time_per_test.items())\n",
    "toolstr.print_table(rows, labels=['test', 'time (s)'])\n",
    "\n",
    "toolstr.print_text_box('Total time per condition')\n",
    "rows = list(time_per_condition.items())\n",
    "toolstr.print_table(rows, labels=['condition', 'time (s)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e565ed6f",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccf325",
   "metadata": {},
   "source": [
    "# Test: eth_getStorageAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test results\n",
    "\n",
    "test_name = 'eth_getStorageAt'\n",
    "results_payload = results_payloads[test_name]\n",
    "results = results_payload['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ff1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show test metadata\n",
    "\n",
    "toolstr.print_text_box(test_name + ' parameters')\n",
    "flood.user_io.print_load_test_summary(results_payload['test'])\n",
    "toolstr.print('- nodes tested:')\n",
    "nodes_df = pl.from_records(list(results_payload['nodes'].values()))\n",
    "toolstr.print_dataframe_as_table(nodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a61486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show result tables\n",
    "\n",
    "flood.user_io.print_metric_tables(results, metrics=metrics, comparison=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9112b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show result figures\n",
    "\n",
    "colors = flood.user_io.get_nodes_plot_colors(nodes=results_payload['nodes'])\n",
    "flood.user_io.plot_load_test_results(\n",
    "    test_name=test_name,\n",
    "    outputs=results,\n",
    "    latency_yscale_log=True,\n",
    "    colors=colors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show errors\n",
    "\n",
    "toolstr.print_text_box('Error messages present in each test')\n",
    "unique_errors = {}\n",
    "for n, name in enumerate(results.keys()):\n",
    "    unique_errors.setdefault(name, set())\n",
    "    unique_errors[name] |= {\n",
    "        error for error_list in results[name]['errors'] for error in error_list\n",
    "    }\n",
    "    print(name)\n",
    "    for error in unique_errors[name]:\n",
    "        print('-', error)\n",
    "    if n != len(results) - 1:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show complete results\n",
    "\n",
    "for name in results.keys():\n",
    "    toolstr.print_text_box(name + \" Complete Results\")\n",
    "    df = pl.DataFrame(results[name])\n",
    "    df = df.drop(\n",
    "        \"status_codes\",\n",
    "        \"errors\",\n",
    "        \"first_request_timestamp\",\n",
    "        \"last_request_timestamp\",\n",
    "        \"last_response_timestamp\",\n",
    "    )\n",
    "    IPython.display.display(df)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
